{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce redundancy and normalize data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove all rows with country not United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'dataset.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a4cb78e813f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'dataset.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns not used in the analysis and rows with NaN values\n",
    "data = data.drop(columns = ['self_employed', 'no_employees', 'tech_company', 'age', 'gender', 'remote_work', 'phys_health_consequence'])\n",
    "data = data.dropna()\n",
    "\n",
    "# Removing column 'country' after keeping 'United States of America' values\n",
    "data = data.drop(columns = 'country')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffled = data.reindex(np.random.permutation(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to normalize the data such that number of values from each state is the same\n",
    "# Loops over the dataframe to find the minimum number of values from any state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the number of data items of each state\n",
    "no_values_states = {}\n",
    "\n",
    "for index, row in data_shuffled.iterrows():\n",
    "  state = row['state']\n",
    "  if state in no_values_states:\n",
    "    no_values_states[state] = no_values_states[state] + 1\n",
    "  else:\n",
    "    no_values_states[state] = 1\n",
    "\n",
    "# Checks the minimum number of values of a state\n",
    "min_values = min(no_values_states.values())\n",
    "\n",
    "print(no_values_states)\n",
    "print(min(no_values_states.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes the states which have less than 10 values in the dataset\n",
    "select_states = {}\n",
    "for st in no_values_states:\n",
    "    if no_values_states[st] >= 10:\n",
    "        select_states[st] = 10\n",
    "        \n",
    "print(select_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops over the dataframe, deletes elements with states not in no_values_states\n",
    "delete_index = []\n",
    "for index, row in data_shuffled.iterrows():\n",
    "    state = row['state']\n",
    "    \n",
    "    if state in select_states:\n",
    "        if select_states[state] <= 0:\n",
    "            delete_index.append(index)\n",
    "        else:\n",
    "            select_states[state] = select_states[state] - 1\n",
    "    else:\n",
    "        delete_index.append(index)\n",
    "\n",
    "print(delete_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = data_shuffled.drop(delete_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bar Graph\n",
    "This is a stacked bar graph. There are three bars for every state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scatter Plot\n",
    "Three scatter plots between number of people with mental disorder and factors benefits, wellness_program, seek_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare the dataset for stacked representation\n",
    "# Dictionary storing the number of 'Yes' answers for every state\n",
    "mental_disorder_yes = {}\n",
    "# Dictionary storing the number of 'No' answers for every state\n",
    "mental_disorder_no = {}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    state = row['state']\n",
    "\n",
    "    if row['mental_disorder_current'] == 'Yes':\n",
    "        if state in mental_disorder_yes:\n",
    "            mental_disorder_yes[state] = mental_disorder_yes[state] + 1\n",
    "        else:\n",
    "            mental_disorder_yes[state] = 1\n",
    "    \n",
    "    if row['mental_disorder_current'] == 'No':\n",
    "        if state in mental_disorder_no:\n",
    "            mental_disorder_no[state] = mental_disorder_no[state] + 1\n",
    "        else:\n",
    "            mental_disorder_no[state] = 1\n",
    "\n",
    "print(mental_disorder_yes)\n",
    "print(mental_disorder_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_disorder = {}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    state = row['state']\n",
    "    if state not in mental_disorder:\n",
    "        mental_disorder[state] = [0, 0]\n",
    "        \n",
    "    if row['mental_disorder_current'] == 'Yes':\n",
    "        mental_disorder[state][0] = mental_disorder[state][0] + 1\n",
    "    elif row['mental_disorder_current'] == 'No':\n",
    "        mental_disorder[state][1] = mental_disorder[state][1] + 1\n",
    "\n",
    "state_list = []\n",
    "yes_list = []\n",
    "no_list = []\n",
    "\n",
    "for state in mental_disorder:\n",
    "    state_list.append(state)\n",
    "    yes_list.append(mental_disorder[state][0])\n",
    "    no_list.append(mental_disorder[state][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_bars = len(mental_disorder)\n",
    "\n",
    "ind = np.arange(num_bars)\n",
    "width = 0.3\n",
    "\n",
    "p1 = plt.bar(ind, yes_list, width)\n",
    "p2 = plt.bar(ind, no_list, width, bottom=yes_list)\n",
    "\n",
    "plt.title('Number of people suffering from mental disorder per state')\n",
    "plt.ylabel('Mental disorders')\n",
    "plt.xticks(ind, state_list)\n",
    "plt.yticks(np.arange(0, 101, 10))\n",
    "plt.legend((p1[0], p2[0]), ('Yes', 'No'))\n",
    "\n",
    "plt.figure(figsize = (1000, 100))\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 5\n",
    "menMeans = (20, 35, 30, 35, 27)\n",
    "womenMeans = (25, 32, 34, 20, 25)\n",
    "menStd = (2, 3, 4, 1, 2)\n",
    "womenStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, menMeans, width, yerr=menStd)\n",
    "p2 = plt.bar(ind, womenMeans, width, bottom=menMeans, yerr=womenStd)\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "plt.yticks(np.arange(0, 81, 10))\n",
    "plt.legend((p1[0], p2[0]), ('Men', 'Women'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl_fig = plt.figure()\n",
    "ax = mpl_fig.add_subplot(111)\n",
    "\n",
    "N = 5\n",
    "menMeans = (20, 35, 30, 35, 27)\n",
    "womenMeans = (25, 32, 34, 20, 25)\n",
    "menStd = (2, 3, 4, 1, 2)\n",
    "womenStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = ax.bar(ind, menMeans, width, color=(0.2588,0.4433,1.0))\n",
    "p2 = ax.bar(ind, womenMeans, width, color=(1.0,0.5,0.62),\n",
    "             bottom=menMeans)\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_xlabel('Groups')\n",
    "ax.set_title('Scores by group and gender')\n",
    "\n",
    "ax.set_xticks(ind + width/2.)\n",
    "ax.set_yticks(np.arange(0, 81, 10))\n",
    "ax.set_xticklabels(('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "\n",
    "plotly_fig = tls.mpl_to_plotly( mpl_fig )\n",
    "\n",
    "# For Legend\n",
    "plotly_fig[\"layout\"][\"showlegend\"] = True\n",
    "plotly_fig[\"data\"][0][\"name\"] = \"Men\"\n",
    "plotly_fig[\"data\"][1][\"name\"] = \"Women\"\n",
    "py.iplot(plotly_fig, filename='stacked-bar-chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "inc_data = data_normal('benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity', 'leave', 'mental_health_consequence', 'coworkers', 'supervisor','mental_vs_physical', 'obs_consequence','family_history', 'mental_disorder_past', 'mental_disorder_current','mental_health_diagnosis', 'work_interfere', 'state')\n",
    "# convert all features to categorical integer values\n",
    "enc = LabelEncoder()\n",
    "for i in inc_data.columns:\n",
    "    inc_data[i] = enc.fit_transform(inc_data[i])\n",
    "    \n",
    "# target is stored in y\n",
    "y = inc_data['mental_health_consequence']\n",
    "\n",
    "# X contains all other features, which we will use to predict target\n",
    "X = inc_data('benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity', 'leave','coworkers', 'supervisor','mental_vs_physical', 'obs_consequence','family_history', 'mental_disorder_past', 'mental_disorder_current','mental_health_diagnosis', 'work_interfere', 'state', axis=1)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# build model and fit on train set\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test set\n",
    "pred_logit = logit.predict(X_test)\n",
    "pred_logit\n",
    "\n",
    "# measure accuracy\n",
    "accuracy_score(y_true = y_test, y_pred = pred_logit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
